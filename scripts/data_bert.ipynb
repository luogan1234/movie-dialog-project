{
 "nbformat": 4,
 "nbformat_minor": 2,
 "metadata": {
  "language_info": {
   "name": "python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "version": "3.6.9-final"
  },
  "orig_nbformat": 2,
  "file_extension": ".py",
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3,
  "kernelspec": {
   "name": "python36964bittorchconda1a439d6d8c364fd69d27dafa7a7c4e60",
   "display_name": "Python 3.6.9 64-bit ('torch': conda)"
  }
 },
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "57\n[556, 485, 347, 313, 300, 299, 296, 296, 291, 282]\n"
    }
   ],
   "source": [
    "movie_data = np.load('movie_data.npy', allow_pickle=True)[()]\n",
    "text_length = []\n",
    "for movie_id, data in movie_data.items():\n",
    "    for conversation in data['conversation']:\n",
    "        for lid, cid, text in conversation:\n",
    "            text_length.append(len(text.split()))\n",
    "text_length.sort(reverse=True)\n",
    "print(text_length[int(len(text_length) * 0.01)])\n",
    "print(text_length[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "m0\n/home/yukuo/anaconda3/envs/torch/lib/python3.6/site-packages/bert_serving/client/__init__.py:299: UserWarning: some of your sentences have more tokens than \"max_seq_len=128\" set on the server, as consequence you may get less-accurate or truncated embeddings.\nhere is what you can do:\n- disable the length-check by create a new \"BertClient(check_length=False)\" when you do not want to display this warning\n- or, start a new server with a larger \"max_seq_len\"\n  '- or, start a new server with a larger \"max_seq_len\"' % self.length_limit)\nm10\nm20\nm30\nm40\nm50\nm60\nm70\nm80\nm90\nm100\nm110\nm120\nm130\nm140\nm150\nm160\nm170\nm180\nm190\nm200\nm210\nm220\nm230\nm240\nm250\nm260\nm270\nm280\nm290\nm300\nm310\nm320\nm330\nm340\nm350\nm360\nm370\nm380\nm390\nm400\nm410\nm420\nm430\nm440\nm450\nm460\nm470\nm480\nm490\nm500\nm510\nm520\nm530\nm540\nm550\nm560\nm570\nm580\nm590\nm600\nm610\n23194\n"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from bert_serving.client import BertClient\n",
    "\n",
    "vocab = set()\n",
    "bc = BertClient()\n",
    "movie_data = np.load('movie_data.npy', allow_pickle=True)[()]\n",
    "for movie_id, data in movie_data.items():\n",
    "    if int(movie_id[1:]) % 20 == 0:\n",
    "        print(movie_id)\n",
    "    processed = []\n",
    "    for conversation in data['conversation']:\n",
    "        text_list = [text for lid, cid, text in conversation]\n",
    "        vecs, tokens = bc.encode(text_list, show_tokens=True)\n",
    "        new_conversation = []\n",
    "        for i in range(len(conversation)):\n",
    "            new_conversation.append((conversation[i][0], conversation[i][1], tokens[i][1:-1], vecs[i]))\n",
    "            for token in tokens[i][1:-1]:\n",
    "                vocab.add(token)\n",
    "        processed.append(new_conversation)\n",
    "    movie_data[movie_id]['conversation'] = processed\n",
    "np.save('movie_data_v1.npy', movie_data)\n",
    "np.save('vocab.npy', list(vocab))\n",
    "print(len(vocab))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "[89, 59, 56, 55, 54]\n"
    }
   ],
   "source": [
    "movie_data = np.load('movie_data_v1.npy', allow_pickle=True)[()]\n",
    "conversation_lens = []\n",
    "for movie_id, data in movie_data.items():\n",
    "    for conversation in data['conversation']:\n",
    "        conversation_lens.append(len(conversation))\n",
    "conversation_lens.sort(reverse=True)\n",
    "print(conversation_lens[:5])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "['can', 'we', 'make', 'this', 'quick', '?', 'ro', '##xa', '##nne', 'ko', '##rri', '##ne', 'and', 'andrew', 'barrett', 'are', 'having', 'an', 'incredibly', 'ho', '##rre', '##ndo', '##us', 'public', 'break', '-', 'up', 'on', 'the', 'quad', '.', 'again', '.']\n"
    }
   ],
   "source": [
    "print(movie_data['m0']['conversation'][0][0][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}